<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Multichannel AAC Audio in Fragmented MP4</title>
    <style>

      *, *::before, *::after {
          box-sizing: border-box;
      }

      /* Remove default margin */
      body,
      h1,
      h2,
      p,
      {
        margin: 0;
      }

      body {
          margin-left: .5em;
          margin-right: .5em;
      }

      #output {
          display: grid;
          grid-template-columns: max-content fit-content(75%);
          column-gap: 1em;
          row-gap: 1em;
          font-family: sans-serif;
          align-items: center;
          max-width: 100%;
      }

      h2 {
          grid-column: span 2;
          margin-top: 1.5em;
          margin-bottom: 0;
          font-size: 1.5em;
      }

      audio {
          width: 100%;
      }

    </style>
  </head>
  <body>
    <h1>Multichannel AAC Audio in Fragmented MP4</h1>
    <p>Every sample encoded with FFMPEG 6.0's native AAC encoder.</p>
    <p>Each sample is loaded with two methods - as an HTML5 Audio element, and via Media Source Extensions (the "HTML Audio" and "MSE" columns, respectively).</p>
    <p>ffmpeg CLI: <code>for f in *.wav; do ffmpeg -loglevel info -i "$f" -c:a aac -movflags faststart+empty_moov+default_base_moof "${f%.wav}.m4a"; done &gt; log.txt 2&gt;&amp;1</code></p>
    <p><a href="media/log.txt">ffmpeg log</a></p>
    <p>Different channel layouts require different signaling, the method used is indicated by the PCE column:</p>
    <ul>
      <li><strong>false</strong> indicates that the channel layout is signaled using the channelConfiguration field
       within the AudioSpecificConfig.</li>
      <li><strong>true</strong> indicates that the channel layout is signaled via Program Config Element
       in the GASpecificConfig.</li>
    </ul>
    <p>In all cases, the channel layout is signaled within the Media Initialization Segment.</p>
    <p>The channels represented in each layout are:</p>
    <ul>
      <li><strong>2.0</strong> Front Left, Front Right</li>
      <li><strong>2.1</strong> Front Left, Front Right, LFE</li>
      <li><strong>3.0</strong> Front Left, Front Right, Front Center</li>
      <li><strong>3.1</strong> Front Left, Front Right, Front Center, LFE</li>
      <li><strong>4.0</strong> Front Left, Front Right, Front Center, Rear Center</li>
      <li><strong>4.1</strong> Front Left, Front Right, Front Center, Rear Center, LFE</li>
      <li><strong>5.0</strong> Front Left, Front Right, Front Center, Rear Left, Rear Right</li>
      <li><strong>5.1</strong> Front Left, Front Right, Front Center, Rear Left, Rear Right, LFE</li>
      <li><strong>6.0</strong> Front Left, Front Right, Front Center, Rear Center, Side Left, Side Right</li>
      <li><strong>6.1</strong> Front Left, Front Right, Front Center, Rear Center, Side Left, Side Right, LFE</li>
      <li><strong>7.0</strong> Front Left, Front Right, Front Center, Rear Left, Rear Right, Side Left, Side Right</li>
      <li><strong>7.1</strong> Front Left, Front Right, Front Center, Rear Left, Rear Right, Side Left, Side Right, LFE</li>
    </ul>
    <p>The layouts listed don't necessarily represent the channel ordering.</p>
    <div id="output"></div>
    <script type="text/javascript">

    const audio_samples = [
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/2_point_0.m4a',
        layout: '2.0',
        pce: false,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/2_point_1.m4a',
        layout: '2.1',
        pce: true,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/3_point_0.m4a',
        layout: '3.0',
        pce: false,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/3_point_1.m4a',
        layout: '3.1',
        pce: true,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/4_point_0.m4a',
        layout: '4.0',
        pce: false,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/4_point_1.m4a',
        layout: '4.1',
        pce: true,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/5_point_0.m4a',
        layout: '5.0',
        pce: false,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/5_point_1.m4a',
        layout: '5.1',
        pce: false,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/6_point_0.m4a',
        layout: '6.0',
        pce: true,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/6_point_1.m4a',
        layout: '6.1',
        pce: true,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/7_point_0.m4a',
        layout: '7.0',
        pce: true,
      },
      { mime: 'audio/mp4;codecs="mp4a.40.2"',
        src: 'media/7_point_1.m4a',
        layout: '7.1',
        pce: false,
      },
    ];

    audio_samples.forEach(function(sample) {
      const mse_audio = document.createElement('audio');
      const html_audio = document.createElement('audio');

      html_audio.src = sample.src;
      html_audio.setAttribute('controls','');
      html_audio.setAttribute('preload','none');

      const mediaSource = new MediaSource();
      mse_audio.src = URL.createObjectURL(mediaSource);
      mse_audio.setAttribute('controls','');
      mse_audio.setAttribute('preload','none');

      mediaSource.addEventListener('sourceopen', function() {
        let sourceBuffer = null;
        URL.revokeObjectURL(mse_audio.src);

        try {
          sourceBuffer = mediaSource.addSourceBuffer(sample.mime);
        } catch(e) {
          console.log(e);
          return;
        }

        sourceBuffer.addEventListener('updateend', function() {
          if(!sourceBuffer.updating && mediaSource.readyState === 'open') {
             mediaSource.endOfStream();
         }
        });

        fetch(sample.src).then(function(response) {
          return response.arrayBuffer();
        }).then(function(data) {
          sourceBuffer.appendBuffer(data);
        });

      });

      /* append everything to table */

      const output = document.getElementById('output');

      const h2 = document.createElement('h2');

      const filename_label = document.createElement('div');
      const filename_value = document.createElement('div');
      const pce_label = document.createElement('div');
      const pce_value = document.createElement('div');
      const htmlaudio_label = document.createElement('div');
      const htmlaudio_value = document.createElement('div');
      const mseaudio_label = document.createElement('div');
      const mseaudio_value = document.createElement('div');

      h2.innerText = 'Channels: ' + sample.layout;

      filename_label.innerText = 'File';
      filename_value.innerText = sample.src;

      pce_label.innerText = 'PCE';
      pce_value.innerHTML = sample.pce ? '<strong>true</strong>' : 'false';

      htmlaudio_label.innerText = 'HTML Audio';
      htmlaudio_value.appendChild(html_audio);

      mseaudio_label.innerText = 'MSE Audio';
      mseaudio_value.appendChild(mse_audio);

      output.appendChild(h2);
      output.appendChild(filename_label);
      output.appendChild(filename_value);
      output.appendChild(pce_label);
      output.appendChild(pce_value);
      output.appendChild(htmlaudio_label);
      output.appendChild(htmlaudio_value);
      output.appendChild(mseaudio_label);
      output.appendChild(mseaudio_value);

    });

    </script>
  </body>
</html>


